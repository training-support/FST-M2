# FST-M2

The following is a checklist of activities that are to be uploaded to the repo:

**JMeter:**
- [ ] Activity 1 - To run a basic load test to demonstarate the basic elements in JMeter - Thread Group, Sampler, Assertions, Listener, Timers
- [ ] Activity 2 - To do a basic load test on a website using Basic Authentication
- [ ] Activity 3 - To implement basic load test using pre and post processors on the training support Selenium site
- [ ] Actvitiy 4 - Connecting to a database and run a load test
- [ ] Actvitiy 5 - Loading data from a CSV file and using that data in a HTTP Request
- [ ] Activity 6 - A demonstration of how the HTTP Link parser works
- [ ] Activity 7 - A Spidering example using the Selenium website
- [ ] Activity 8 - To run a basic load test on the Selenium site for Training Support

**JMeter Project:**
- [ ] Activity 1 - Recording a load test
- [ ] Activity 2 - Load testing an API with Authentication
- [ ] Activity 3 - Petstore API

**Docker:**
- [ ] Activity 1 - Create and run a docker container that has a NodeJS app inside it
- [ ] Activity 2 - Create and run a NodeJS app along with a DB container using docker networks
- [ ] Activity 3 - Create and run a NodeJS app along with a persistently stored DB container using docker-compose
- [ ] Activity 4 - Create and run a complex application that has multiple services

**Kubernetes:**
- [ ] Activity 1 - Create a configuration file to setup and run a simple Kubernetes cluster
- [ ] Activity 2 - Create a configuration file to setup and run an application with multiple services running in a cluster
- [ ] Activity 3 - Create a configuration file to setup and run a replicaset for an nginx pod
- [ ] Activity 4 - Create a configuration file to setup and run an application with multiple services and persistent storage running in a cluster

**Ansible:**
- [ ] Activity 1 - Write a simple Ansible playbook
- [ ] Activity 2 - Write an Ansible playbook to configure an application server

**Docker Project:**
- [ ] The following files have to be uploaded: Dockerfile.dev, Dockerfile.prod, docker-compose.yml

**Kubernetes Project:**
- [ ] The following files have to be uploaded: api-deployment.yml, api-cluster-ip-service.yml, postgres-deployment.yml, postgres-cluster-ip-service.yml, ingress-service.yml, database=persistent-volume-claim.yml

**Hadoop:**
- [ ] Activity 1 - To manipulate files in the Hadoop Distributed File System (HDFS)
- [ ] Activity 2 - MapReduce using Pig on Text File
- [ ] Activity 3 - MapReduce using Pig on CSV File
- [ ] Activity 4 - WordCount using Hive on Text file
- [ ] Activity 5 - Analyzing Employee Data using Beeline

**Spark:**
- [ ] Activity 1 - Using Notebooks to run Spark computations text files
- [ ] Activity 2 - Using Notebooks to run Spark computations on CSV Files
- [ ] Activity 3 - Using Notebooks to run Spark computations on JSON Files

**Informatica(Screenshots):**
- [ ] Activity 1 - Using Informatica to perform a simple Filter Mapping
- [ ] Activity 2 - Using Informatica to perform Mapping a complex Filter Mapping with the results bring routed through other transformations
- [ ] Activity 3 - Using Informatica to perform Mapping with the Lookup Transformation
- [ ] Activity 4 - Using Informatica to perform a Mapping with the Joiner Transfomation
- [ ] Activity 5 - Using Informatica to perform a Mapping that uses a database View

**Hadoop Project:**
- [ ] Activity 1 - Count the number of lines spoken by each character(Pig)
- [ ] Activity 2 - Count the number of lines spoken by each character(Hive)
- [ ] Activity 3 - Count the number of dialogues where the name "Luke" is said in EpisodeIV(Hive)
- [ ] Activity 4 - Create a Mapping in Informatica Cloud(Informatica Screenshot)
